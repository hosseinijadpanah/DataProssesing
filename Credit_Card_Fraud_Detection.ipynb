{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Credit card fraud detection is a critical task in the financial industry to prevent unauthorized transactions and protect consumers from financial losses. Both machine learning and deep learning techniques have been extensively applied to address this problem. Here's an overview of how each approach can be used:\n",
        "\n",
        "**Machine Learning for Credit Card Fraud Detection**:\n",
        "\n",
        "- Supervised Learning: In supervised learning, historical transaction data labeled as either fraudulent or non-fraudulent is used to train classification models. Common algorithms include logistic regression, decision trees, random forests, support vector machines (SVM), and ensemble methods like gradient boosting classifiers. These models learn patterns and features from the data to classify new transactions as fraudulent or legitimate.\n",
        "\n",
        "- Anomaly Detection: Anomaly detection techniques are also widely used for fraud detection, especially in cases where fraudulent transactions are rare and hard to distinguish from normal behavior. Algorithms like Isolation Forest, Local Outlier Factor (LOF), and One-Class SVM are commonly used for detecting anomalies in credit card transactions based on deviations from normal behavior patterns.\n",
        "\n",
        "**Deep Learning for Credit Card Fraud Detection**:\n",
        "\n",
        "- Neural Networks: Deep learning models, particularly neural networks, have shown promise in detecting complex patterns and nonlinear relationships in high-dimensional data like credit card transactions. Architectures like feedforward neural networks, convolutional neural networks (CNNs), and recurrent neural networks (RNNs) can be employed for fraud detection tasks.\n",
        "Autoencoders: Autoencoder architectures, which consist of an encoder and a decoder, can be used for unsupervised learning-based anomaly detection. The model learns to reconstruct input data and anomalies are identified by large reconstruction errors.\n",
        "\n",
        "\n",
        "- Graph Neural Networks (GNNs): GNNs can capture the relational structure between entities (e.g., accounts, merchants) in transaction networks. By modeling transaction graphs, GNNs can learn to detect fraudulent patterns that involve complex relationships between entities.\n",
        "Challenges and Considerations:\n",
        "\n",
        "Imbalanced Data: Credit card fraud datasets are typically highly imbalanced, with fraudulent transactions being a small fraction of the total. Dealing with imbalanced data requires careful selection of evaluation metrics, sampling techniques, and model optimization strategies.\n",
        "\n",
        "Feature Engineering: Extracting relevant features from transaction data is crucial for building effective fraud detection models. Features may include transaction amount, time, location, user behavior patterns, and more. Feature engineering techniques play a vital role in improving model performance.\n",
        "\n",
        "Real-Time Detection: In practice, credit card fraud detection systems need to operate in real-time to block suspicious transactions as they occur. This requires efficient model inference and integration with transaction processing systems.\n",
        "\n",
        "In summary, both machine learning and deep learning techniques offer effective approaches for credit card fraud detection, each with its strengths and considerations. The choice of approach depends on factors such as the nature of the data, the complexity of fraud patterns, and the requirements of the deployment environment."
      ],
      "metadata": {
        "id": "AK7kDGA04JWB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "505nLaB34Cc-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data= pd.read_csv(\"creditcard.csv\")\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "PEWOYF7j4fZX",
        "outputId": "cc3292b7-55cb-4aae-8c18-066f750d075d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
              "1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
              "2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
              "3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
              "4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
              "\n",
              "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
              "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
              "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
              "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
              "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
              "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
              "\n",
              "        V26       V27       V28  Amount  Class  \n",
              "0 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
              "1  0.125895 -0.008983  0.014724    2.69    0.0  \n",
              "2 -0.139097 -0.055353 -0.059752  378.66    0.0  \n",
              "3 -0.221929  0.062723  0.061458  123.50    0.0  \n",
              "4  0.502292  0.219422  0.215153   69.99    0.0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d9e45b90-5ba7-413c-9b8a-c3b0b7240b1d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d9e45b90-5ba7-413c-9b8a-c3b0b7240b1d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d9e45b90-5ba7-413c-9b8a-c3b0b7240b1d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d9e45b90-5ba7-413c-9b8a-c3b0b7240b1d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-60012630-f8ba-47be-bf59-aade70623278\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-60012630-f8ba-47be-bf59-aade70623278')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-60012630-f8ba-47be-bf59-aade70623278 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.unique(data[\"Class\"] , return_counts=True)\n",
        "\n",
        "# its mean 15862 good data\n",
        "# 73 data with label 1 as Fraud\n",
        "# contamination = dirty/clean= 73/15862   ----> its give us estimation of ration of dirty to clean data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHPm-f9Q5CNy",
        "outputId": "4a2a94f2-ae67-4dfc-cf66-e329158a802a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 0.,  1., nan]), array([15862,    73,     1]))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with missing values\n",
        "data.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "QtsDg_FN9WFu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import LocalOutlierFactor\n"
      ],
      "metadata": {
        "id": "0J5ArxUb5-7h"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the feature matrix X\n",
        "X = data.drop(\"Class\", axis=1)\n",
        "\n",
        "# Create the LOF model\n",
        "LOF = LocalOutlierFactor(n_neighbors=10, contamination=0.004)\n",
        "\n",
        "# Fit the model and predict outliers\n",
        "y_predict = LOF.fit_predict(X)"
      ],
      "metadata": {
        "id": "La2q6SIk7P1M"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FP7dLd9G8IUa",
        "outputId": "d4e3d29e-ba5d-49c6-9f81-bae2ecca500a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 ... 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(y_predict , return_counts=True)\n",
        "# -1 ---> Fraud"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7k5q30pm-pw1",
        "outputId": "41a9ad3a-8424-4a51-cc78-e5b4b8c88b4c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-1,  1]), array([   64, 15871]))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict[y_predict==1] = 0\n",
        "y_predict[y_predict==-1] = 1"
      ],
      "metadata": {
        "id": "1eh8GhwO_IF2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make similar to our dataset , Fraud---> 1 , clean--->0\n",
        "np.unique(y_predict , return_counts=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkUBTv1D_df7",
        "outputId": "d9c6b1b5-18e0-4fb4-fe9d-b5f3d4a6e414"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1]), array([15871,    64]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n"
      ],
      "metadata": {
        "id": "FrdFuQMvAwAX"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true= data[\"Class\"]\n"
      ],
      "metadata": {
        "id": "QYkKvBrzBI7o"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(metrics.classification_report(y_true=y_true, y_pred=y_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRHaNSuJBTfW",
        "outputId": "2f1aeac3-eadf-4d1a-865e-4c0052b08758"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00     15862\n",
            "         1.0       0.06      0.05      0.06        73\n",
            "\n",
            "    accuracy                           0.99     15935\n",
            "   macro avg       0.53      0.53      0.53     15935\n",
            "weighted avg       0.99      0.99      0.99     15935\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results indicate that **the model's performance is not satisfactory**, especially for class 1 (the minority class). Here are some observations:\n",
        "\n",
        "Precision and Recall for Class 1 (Anomalies): **The precision and recall** **values for class 1 are very low**(0.06 and 0.05, respectively). This means that out of all the instances predicted as anomalies, only **a very small** fraction **are actually true anomalies**(precision), and the model is also missing a large number of true anomalies (recall).\n",
        "\n",
        "F1-score: The F1-score, which is the harmonic mean of precision and recall, is also very low for class 1 (0.06). This indicates poor overall performance in identifying anomalies.\n",
        "\n",
        "Imbalanced Dataset: The dataset seems to be heavily imbalanced, with a large number of instances belonging to class 0 (normal) and a very small number belonging to class 1 (anomalies). This imbalance can affect the model's ability to learn patterns in the minority class and may lead to biased results.\n",
        "\n",
        "Accuracy: While the overall accuracy of 99% may seem high, it can be misleading in the presence of imbalanced data. In this case, the high accuracy is mainly due to the large number of correctly predicted instances in class 0, but it does not reflect the model's performance on the minority class.\n",
        "\n",
        "In summary, the model's performance, especially for detecting anomalies (class 1), is not satisfactory, and further investigation and possibly model improvement are needed."
      ],
      "metadata": {
        "id": "E8YThDF5B5kL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Python Outlier Detection(PyOD)"
      ],
      "metadata": {
        "id": "6YupyXwNE8yn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In PyOD, the choice between angle-based and distance-based methods depends on the specific algorithm being used for outlier detection.\n",
        "\n",
        "**Angle-Based Methods**  (Sklearn is not angle based):\n",
        "\n",
        "Angle-based methods typically measure the angle between data points in a high-dimensional space. These methods are often used in outlier detection algorithms based on subspace analysis or nearest neighbors.\n",
        "One example of an angle-based method in PyOD is the Angle-based Outlier Detector (**ABOD**), which computes the variance of angles between a data point and all other data points. Outliers are identified based on the variance of these angles.\n",
        "\n",
        "**Angle-based methods can be effective when dealing with data that**       **exhibit complex geometric structures or non-linear relationships.**\n",
        "\n",
        "\n",
        "Distance-Based Methods:\n",
        "\n",
        "Distance-based methods measure the distance between data points in the feature space. Outliers are often identified as data points that are farthest from the majority of the data.\n",
        "Many popular outlier detection algorithms in PyOD, such as k-Nearest Neighbors (kNN), Isolation Forest, and Local Outlier Factor (LOF), are distance-based methods.\n",
        "\n",
        "\n",
        "Distance-based methods are suitable for detecting outliers in both low-dimensional and high-dimensional datasets. They are particularly effective when outliers are defined as instances that are significantly distant from the rest of the data points.\n",
        "\n",
        "\n",
        "\n",
        "Both angle-based and distance-based methods have their advantages and limitations, and the choice between them depends on factors such as the nature of the data, the desired level of interpretability, and the computational requirements. PyOD provides a variety of algorithms that cover both types of methods, allowing users to select the most appropriate approach based on their specific needs and the characteristics of the dataset."
      ],
      "metadata": {
        "id": "zzGup3pcEglM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyOD (Python Outlier Detection) is a comprehensive Python library for detecting outliers and anomalies in data. It provides a wide range of algorithms and tools for various anomaly detection tasks. Here's an overview of PyOD's application in anomaly detection:\n",
        "\n",
        "Wide Range of Algorithms:\n",
        "\n",
        "PyOD offers a rich collection of outlier detection algorithms, including both traditional statistical methods and modern machine learning techniques. These algorithms cover various approaches such as proximity-based, linear models, clustering-based, and ensemble methods.\n",
        "Some popular algorithms included in PyOD are Isolation Forest, Local Outlier Factor (LOF), k-Nearest Neighbors (kNN), One-Class SVM, Principal Component Analysis (PCA), and more.\n",
        "\n",
        "Flexibility and Customization:\n",
        "\n",
        "PyOD provides a unified API interface for different algorithms, making it easy to compare and evaluate multiple methods on the same dataset.\n",
        "Users can customize the parameters and settings of each algorithm to adapt to different data characteristics and application requirements.\n",
        "\n",
        "Scalability and Performance:\n",
        "\n",
        "Many algorithms in PyOD are designed to handle large-scale datasets efficiently. For example, Isolation Forest and kNN-based methods have linear time complexity with respect to the number of data points.\n",
        "PyOD also supports parallel processing and multi-threading to further enhance performance on multicore systems.\n",
        "\n",
        "Evaluation and Model Selection:\n",
        "\n",
        "PyOD includes utilities for evaluating and benchmarking outlier detection algorithms. Users can assess the performance of different methods using standard metrics such as precision, recall, F1-score, and area under the ROC curve (AUC-ROC).\n",
        "The library provides functions for cross-validation, model selection, hyperparameter tuning, and visualization of evaluation results.\n",
        "\n",
        "Application Areas:\n",
        "\n",
        "PyOD can be applied to various domains and use cases where anomaly detection is required, including fraud detection, network security, IoT (Internet of Things) monitoring, financial transactions, healthcare, and more.\n",
        "It is suitable for both batch processing and real-time anomaly detection scenarios.\n",
        "\n",
        "Overall, PyOD is a powerful and versatile library for anomaly detection tasks, offering a comprehensive set of algorithms, tools, and utilities to support a wide range of applications. It simplifies the process of implementing, evaluating, and deploying outlier detection solutions, making it accessible to both researchers and practitioners in the field."
      ],
      "metadata": {
        "id": "XSodX9bTEg2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyod\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlVgiwN3HUDD",
        "outputId": "e4adff34-9483-497d-b914-ce3a878e1113"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyod\n",
            "  Downloading pyod-1.1.3.tar.gz (160 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.5/160.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from pyod) (1.3.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from pyod) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.10/dist-packages (from pyod) (1.25.2)\n",
            "Requirement already satisfied: numba>=0.51 in /usr/local/lib/python3.10/dist-packages (from pyod) (0.58.1)\n",
            "Requirement already satisfied: scipy>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from pyod) (1.11.4)\n",
            "Requirement already satisfied: scikit_learn>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from pyod) (1.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pyod) (1.16.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51->pyod) (0.41.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>=0.22.0->pyod) (3.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyod) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyod) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyod) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyod) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyod) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyod) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyod) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyod) (2.8.2)\n",
            "Building wheels for collected packages: pyod\n",
            "  Building wheel for pyod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyod: filename=pyod-1.1.3-py3-none-any.whl size=190251 sha256=e0747c081ca776bd4e430b9c0c7b519ffec5e32ed5226c3d95973daf4b978c97\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/f8/db/124d43bec122d6ec0ab3713fadfe25ebed8af52ec561682b4e\n",
            "Successfully built pyod\n",
            "Installing collected packages: pyod\n",
            "Successfully installed pyod-1.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pyod\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sb-Ft0rEIMmd",
        "outputId": "ebd9e91c-9c7f-405b-edf0-7cc6c90835aa"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyod in /usr/local/lib/python3.10/dist-packages (1.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from pyod) (1.3.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from pyod) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.10/dist-packages (from pyod) (1.25.2)\n",
            "Requirement already satisfied: numba>=0.51 in /usr/local/lib/python3.10/dist-packages (from pyod) (0.58.1)\n",
            "Requirement already satisfied: scipy>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from pyod) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from pyod) (1.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pyod) (1.16.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51->pyod) (0.41.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.0->pyod) (3.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyod) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyod) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyod) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyod) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyod) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyod) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyod) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyod) (2.8.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with PyOD-ABOD----> angle\n",
        "from pyod.models.abod import ABOD\n",
        "from sklearn import metrics\n",
        "\n",
        "# Your code to load the dataset and create the feature matrix X\n",
        "\n",
        "# Create the ABOD model\n",
        "abod_model = ABOD(contamination=0.004)\n",
        "\n",
        "# Fit the model and predict outliers\n",
        "abod_model.fit(X)\n",
        "y_predict = abod_model.predict(X)\n",
        "\n",
        "# Get true labels\n",
        "y_true = data[\"Class\"]\n",
        "\n",
        "# Calculate and print classification report\n",
        "print(metrics.classification_report(y_true=y_true, y_pred=y_predict))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSbKiI8cG1h0",
        "outputId": "48c98977-6742-4e9f-930f-f03505ebef83"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3787: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:163: RuntimeWarning: invalid value encountered in divide\n",
            "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:198: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00     15862\n",
            "         1.0       0.06      0.04      0.05        73\n",
            "\n",
            "    accuracy                           0.99     15935\n",
            "   macro avg       0.53      0.52      0.52     15935\n",
            "weighted avg       0.99      0.99      0.99     15935\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with PyOD-LOF----> distance\n",
        "from pyod.models.lof import LOF\n",
        "from sklearn import metrics\n",
        "\n",
        "# Create the feature matrix X\n",
        "X = data.drop(\"Class\", axis=1)\n",
        "\n",
        "# Create the LOF model\n",
        "lof_model = LOF(n_neighbors=10, contamination=0.004)\n",
        "\n",
        "# Fit the model and predict outliers\n",
        "lof_model.fit(X)\n",
        "y_predict = lof_model.predict(X)\n",
        "\n",
        "# Get true labels\n",
        "y_true = data[\"Class\"]\n",
        "\n",
        "# Calculate and print classification report\n",
        "print(metrics.classification_report(y_true=y_true, y_pred=y_predict))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tvaUGGOG1xf",
        "outputId": "7907fa11-e8a4-4067-cefc-820d26751173"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00     15862\n",
            "         1.0       0.05      0.03      0.03        73\n",
            "\n",
            "    accuracy                           0.99     15935\n",
            "   macro avg       0.52      0.51      0.52     15935\n",
            "weighted avg       0.99      0.99      0.99     15935\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyod.models.knn import KNN\n",
        "from sklearn import metrics\n",
        "\n",
        "# Create the feature matrix X\n",
        "X = data.drop(\"Class\", axis=1)\n",
        "\n",
        "# Create the KNN model\n",
        "knn_model = KNN(contamination=0.004)\n",
        "\n",
        "# Fit the model and predict outliers\n",
        "knn_model.fit(X)\n",
        "y_predict = knn_model.predict(X)\n",
        "\n",
        "# Get true labels\n",
        "y_true = data[\"Class\"]\n",
        "\n",
        "# Calculate and print classification report\n",
        "print(metrics.classification_report(y_true=y_true, y_pred=y_predict))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRcj2TqiHt9b",
        "outputId": "57b8fb51-f904-4527-89c1-f60471c49b52"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00     15862\n",
            "         1.0       0.04      0.03      0.03        73\n",
            "\n",
            "    accuracy                           0.99     15935\n",
            "   macro avg       0.52      0.51      0.51     15935\n",
            "weighted avg       0.99      0.99      0.99     15935\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IsolationForest"
      ],
      "metadata": {
        "id": "so7tIKueKdBW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Isolation Forest is an algorithm used for anomaly detection, particularly in high-dimensional datasets. It works by isolating anomalies in the dataset by randomly selecting a feature and then randomly selecting a split value between the maximum and minimum values of the selected feature. This process is repeated recursively until all instances are isolated.\n",
        "\n",
        "The main idea behind Isolation Forest is that anomalies are likely to be isolated in fewer splits compared to normal instances, as they tend to have attribute values that are very different from those of normal instances. Therefore, the average path length to isolate an anomaly is expected to be shorter than that of a normal instance.\n",
        "\n",
        "Isolation Forest has several advantages:\n",
        "\n",
        "Efficiency: Isolation Forest can efficiently handle large datasets with high dimensionality because it only needs to randomly select a subset of features for splitting at each step.\n",
        "\n",
        "Scalability: It has a computational complexity of O(n log n), making it scalable to large datasets.\n",
        "\n",
        "Robustness: Isolation Forest is less affected by outliers and noise in the dataset compared to other algorithms.\n",
        "\n",
        "No assumptions about the data: It does not make any assumptions about the distribution of the data, making it suitable for a wide range of applications.\n",
        "\n",
        "Whether Isolation Forest performs better than other algorithms like PyOD (Python Outlier Detection) and LocalOutlierFactor (LOF) depends on various factors such as the characteristics of the dataset, the nature of the anomalies, and the specific requirements of the application.\n",
        "\n",
        "In some cases, Isolation Forest may outperform other algorithms, especially when dealing with high-dimensional data or when anomalies are well-separated from normal instances. However, it's essential to evaluate the performance of different algorithms empirically on the specific dataset to determine which one works best for a particular use case. Additionally, ensemble methods like Isolation Forest can also be combined with other anomaly detection techniques for improved performance."
      ],
      "metadata": {
        "id": "a9VqahGKJPcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn import metrics\n",
        "\n",
        "# Create the feature matrix X\n",
        "X = data.drop(\"Class\", axis=1)\n",
        "\n",
        "# Create the Isolation Forest model\n",
        "isoforest_model = IsolationForest(contamination=0.004, random_state=42)\n",
        "\n",
        "# Fit the model and predict outliers\n",
        "isoforest_model.fit(X)\n",
        "y_predict = isoforest_model.predict(X)\n",
        "\n",
        "# Convert predictions to binary labels (0: inliers, 1: outliers)\n",
        "y_predict_binary = np.where(y_predict == -1, 1, 0)\n",
        "\n",
        "# Get true labels\n",
        "y_true = data[\"Class\"]\n",
        "\n",
        "# Calculate and print classification report\n",
        "print(metrics.classification_report(y_true=y_true, y_pred=y_predict_binary))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0lDNKZkJPsz",
        "outputId": "af34e7b2-8a80-419d-8068-277e44882634"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00     15862\n",
            "         1.0       0.58      0.51      0.54        73\n",
            "\n",
            "    accuracy                           1.00     15935\n",
            "   macro avg       0.79      0.75      0.77     15935\n",
            "weighted avg       1.00      1.00      1.00     15935\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result looks reasonable, but it depends on the specific requirements and context of your anomaly detection task.\n",
        "\n",
        "Here's a breakdown of the metrics:\n",
        "\n",
        "Precision (for class 1): Precision measures the ratio of true positive predictions to the total number of positive predictions made by the model. In this case, it **indicates that about 58% of the instances predicted** as anomalies **are actually true anomalies**.\n",
        "\n",
        "Recall (for class 1): Recall measures the ratio of true positive predictions to the total number of actual positive instances in the dataset. It indicates that the model **correctly identifies around 51% of the actual anomalies**.\n",
        "\n",
        "F1-score (for class 1): The F1-score is the harmonic mean of precision and recall. It provides a balance between precision and recall. In this case, the F1-score for class 1 is 0.54, which suggests a reasonable balance between precision and recall.\n",
        "\n",
        "Accuracy: Accuracy measures the ratio of correctly predicted instances to the total number of instances in the dataset. An accuracy of 1.00 indicates that the model correctly classifies all instances, both normal and anomalous.\n",
        "\n",
        "Macro avg and weighted avg: These metrics provide the average scores across all classes. They give a general overview of the model's performance across all classes.\n",
        "\n",
        "Overall, the model achieves high accuracy and precision for the majority class (normal instances), but it has relatively lower recall and F1-score for the minority class (anomalies). Depending on your specific requirements, you may need to adjust the model or explore other techniques to improve its performance on detecting anomalies."
      ],
      "metadata": {
        "id": "2AQ5NTLxJ2_Y"
      }
    }
  ]
}